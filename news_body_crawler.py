from flask import Flask, request, jsonify
import requests
from bs4 import BeautifulSoup
import pymysql
import time

app = Flask(__name__)

# âœ… DB ì„¤ì • (RDS ì ‘ì† ì •ë³´)
DB_CONFIG = {
    'host': 'news-db.cjg2aaai646f.ap-northeast-2.rds.amazonaws.com',
    'user': 'songsungmin',
    'password': 'password0419',
    'database': 'newsdb',
    'port': 3306
}

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
                  '(KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36'
}

article_contents = {}
failed_articles = {}

# âœ… ë³¸ë¬¸ í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_articles_by_list(id_url_list):
    conn = pymysql.connect(**DB_CONFIG)
    cursor = conn.cursor()
    result = []

    for item in id_url_list:
        news_id = item.get("news_id")  # âœ… ìˆ˜ì •ëœ ì»¬ëŸ¼ëª…
        url = item.get("url")

        if not news_id or not url:
            continue

        print(f"\nğŸŒ ë³¸ë¬¸ ìš”ì²­ ì¤‘ (news_id: {news_id}): {url}")

        for attempt in range(3):
            try:
                res = requests.get(url, headers=headers, timeout=10)
                res.raise_for_status()
                soup = BeautifulSoup(res.text, 'html.parser')
                content_tag = soup.select_one('#dic_area')
                content = content_tag.get_text(strip=True) if content_tag else '[ë³¸ë¬¸ ì—†ìŒ]'

                # âœ… DBì— ë³¸ë¬¸ ì €ì¥
                cursor.execute(
                    "UPDATE news SET content = %s WHERE news_id = %s",
                    (content, news_id)
                )
                article_contents[news_id] = {
                    "news_id": news_id,
                    "url": url,
                    "content": content
                }
                print(f"âœ… ë³¸ë¬¸ ì €ì¥ ì™„ë£Œ - news_id: {news_id}")
                print(f"ğŸ§  ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°: {content[:100]}...")
                result.append(news_id)
                break

            except Exception as e:
                print(f"âš ï¸ ì¬ì‹œë„ {attempt + 1} ì‹¤íŒ¨ - news_id: {news_id} | {e}")
                time.sleep(2)

        else:
            print(f"âŒ ìµœì¢… ì‹¤íŒ¨ - news_id: {news_id}")
            failed_articles[news_id] = url

        time.sleep(2)

    conn.commit()
    conn.close()
    return result

# âœ… POST ìš”ì²­ ì²˜ë¦¬
@app.route('/trigger', methods=['POST'])
def trigger():
    data = request.get_json()
    id_url_list = data.get("articles", [])  # ì˜ˆ: [{ "news_id": 12, "url": "..." }]
    updated_ids = crawl_articles_by_list(id_url_list)

    return jsonify({
        "message": "ë³¸ë¬¸ í¬ë¡¤ë§ ì™„ë£Œ",
        "count": len(updated_ids),
        "ids": updated_ids,
        "fail_count": len(failed_articles),
        "failed_ids": list(failed_articles.keys())
    })

# âœ… ìƒíƒœ í™•ì¸ìš©
@app.route('/')
def status():
    return jsonify({
        "message": "ë³¸ë¬¸ í¬ë¡¤ëŸ¬ ì„œë²„ ì‹¤í–‰ ì¤‘",
        "stored_news_ids": list(article_contents.keys()),
        "fail_count": len(failed_articles)
    })

# âœ… ì‹¤í–‰
if __name__ == '__main__':
    print("ğŸ§  ë³¸ë¬¸ í¬ë¡¤ëŸ¬ ì„œë²„ ì‹¤í–‰ ì¤‘ (5003 í¬íŠ¸)...")
    app.run(host='0.0.0.0', port=5003, debug=True)
